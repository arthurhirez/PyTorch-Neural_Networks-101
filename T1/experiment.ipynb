{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from Autoencoder import Autoencoder\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "\n",
    "from Dense import Dense\n",
    "\n",
    "from utils import *"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb7e44c65498516d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch_exp = [100, 500]\n",
    "train_exp = [750, 1500, 3000, 7500, 10000, 15000]\n",
    "# batch_exp = [2**x for x in range(9, 4, -1)]\n",
    "batch_exp = [512, 256, 128, 64, 32]\n",
    "\n",
    "repetitions = 3\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in epoch_exp:\n",
    "    etime_batch = time.time()\n",
    "    for train_size in train_exp:\n",
    "        X_train, _, _, _ = load_MNIST(train_size = train_size, test_size = int(0.2*train_size))\n",
    "        ttime_batch = time.time()\n",
    "        for batch in batch_exp:\n",
    "            stime_batch = time.time()\n",
    "            for rep in range(repetitions):\n",
    "                encoder = Autoencoder(lr = 1e-1)\n",
    "                \n",
    "                encoder.add(Dense(28*28, 350))\n",
    "                encoder.add(Dense(350, 128, output_layer = True))\n",
    "                \n",
    "                encoder.fit(X_train, X_train, epochs = epoch, batch_size = batch, verbose = False)\n",
    "                # report_encode(X_test, X_test, encoder)\n",
    "                # encoder.plot_loss()\n",
    "                encoder.save(f\"experiments/encoder_epoch_{epoch}_{train_size}_{batch}_{rep}.pkl\")\n",
    "            print(f\"Terminou batch {batch}:\\t{time.time() - stime_batch:.2f}s\")\n",
    "        print('-----***-----'*10)\n",
    "        print(f\"Terminou treino {train_size}:\\t{time.time() - ttime_batch:.2f}s\")\n",
    "        print('-----***-----'*10 + '\\n')\n",
    "    print('-----***-----'*10)\n",
    "    print(f\"\\nTerminou epoca {epoch}:\\t{time.time() - etime_batch:.2f}s\")\n",
    "    print(['//***//']*10 + ['\\n'])\n",
    "print('-----***-----'*10)\n",
    "print(f\"\\nTempo total:\\t{time.time() - start_time:.2f}s\")\n",
    "print('-----***-----'*10 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch_exp = [100, 500]\n",
    "train_exp = [750, 1500, 3000, 7500, 10000]\n",
    "# batch_exp = [2**x for x in range(9, 4, -1)]\n",
    "batch_exp = [512, 256, 128, 64, 32]\n",
    "repetitions = 3\n",
    "losses = {}\n",
    "\n",
    "columns = ['Batch Size', 'Epochs', 'Train Size', 'Train Time', 'MSE Train', 'rep', 'error_trace']\n",
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "# Load models and retrieve losses\n",
    "for epoch in epoch_exp:\n",
    "    for train_size in train_exp:\n",
    "        for batch in batch_exp:\n",
    "            epoch_losses = []\n",
    "            error_trace = []\n",
    "            for rep in range(repetitions):\n",
    "                filename = f\"experiments/encoder_epoch_{epoch}_{train_size}_{batch}_{rep}.pkl\"\n",
    "                if os.path.exists(filename):\n",
    "                    encoder = Autoencoder.load(filename)  # Load model\n",
    "                    epoch_losses.append(encoder.mse_train)  # Retrieve last MSE from training\n",
    "                    error_trace.append(encoder.err_trace)\n",
    "                    data = {'Batch Size': encoder.batch,\n",
    "                            'Epochs': encoder.epochs,\n",
    "                            'Train Size': encoder.size_train,\n",
    "                            'Train Time': encoder.time_train,\n",
    "                            'MSE Train': encoder.mse_train,\n",
    "                            'rep': rep,\n",
    "                            'error_trace': np.array(encoder.err_trace)}\n",
    "                    df.loc[len(df)] = data\n",
    "            losses[(epoch, train_size, batch)] = ((np.mean(epoch_losses), np.std(epoch_losses, ddof=1)),)\n",
    "\n",
    "df.loc[(df['Batch Size'] == 32) & \n",
    "       (df['Epochs'] == 100) & \n",
    "       (df['Train Size'] == 7500) & \n",
    "       (df['rep'] == 0), 'Train Time'] = 207.167867"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb7741054a368469"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
